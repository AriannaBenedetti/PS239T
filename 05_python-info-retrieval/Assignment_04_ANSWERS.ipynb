{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Set: Information Retrieval\n",
    "\n",
    "## Part 2: Structuring + Manipulating Data\n",
    "\n",
    "In this problem set, you'll be continuing to work with the data you imported during lecture. You'll be structuring and manipulating that data to turn it into a tabular dataset.\n",
    "\n",
    "Specifically you'll be:\n",
    "\n",
    "1. Splitting the text into \"chunks\" that correspond to major sections\n",
    "2. Parse those chunks into main text and subitems\n",
    "3. Repeat steps 1-2 by creating a function and looping through documents\n",
    "4. Get information about specific recommendations\n",
    "5. Write a csv file from our data\n",
    "\n",
    "To get started, import the following modules and run the code from lecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import csv\n",
    "from operator import itemgetter\n",
    "from itertools import groupby"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preface: Run Code from Lecture\n",
    "\n",
    "Run the code below to get started"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# merge lines so that each number starts with a number\n",
    "def mergeLines(l):\n",
    "    '''\n",
    "    This function takes in a list of lines `l` and merge broken paragraph lines \n",
    "    (merge all lines if they don't start with a number)\n",
    "    '''\n",
    "    i = 0\n",
    "    while i < len(l):\n",
    "        if not l[i][0].isdigit():\n",
    "            l[i-1:i+1] = [' '.join(l[i-1:i+1])]\n",
    "        else:\n",
    "            i = i+1\n",
    "    return(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing afghanistan2014.txt...\n",
      "processing albania2014.txt...\n",
      "processing bangladesh2013.txt...\n",
      "processing belize2013.txt...\n",
      "processing bolivia2014.txt...\n",
      "processing botswana2013.txt...\n",
      "processing cotedivoire2014.txt...\n",
      "processing djibouti2013.txt...\n",
      "processing elsalvador2014.txt...\n",
      "processing fiji2014.txt...\n",
      "processing jordan2013.txt...\n",
      "processing kazakhstan2014.txt...\n",
      "processing monaco2013.txt...\n",
      "processing montenegro2013.txt...\n",
      "processing sanmarino2014.txt...\n",
      "processing serbia2013.txt...\n",
      "processing turkmenistan2013.txt...\n",
      "processing tuvalu2013.txt...\n"
     ]
    }
   ],
   "source": [
    "l=[]\n",
    "dir = 'data/txts'\n",
    "for file_name in os.listdir(dir):\n",
    "    broken = []\n",
    "    if file_name.endswith(\".txt\"):\n",
    "        print 'processing ' + file_name + '...'\n",
    "        try:\n",
    "            dic = {}\n",
    "            dic['country'] = file_name[:-8]\n",
    "            dic['year'] = file_name[-8:-4]\n",
    "            f = open(dir + '/' + file_name,'rU')\n",
    "            text = f.read() # read in text\n",
    "            f.close\n",
    "            text = text.split('\\n') # make a list\n",
    "            text = filter(None, text) # get rid of empty string items       \n",
    "             \n",
    "            # take only the conclusions and/or recommendations section\n",
    "            ConclusionsStart = text.index([line for line in text if \"conclusions and/or recommendations\" in line.lower()][1]) #startin from bottom\n",
    "            ConclusionsEnd = text.index([line for line in text if \"conclusions and/or recommendations\" in line.lower()][2]) # the last one is the disclaimer\n",
    "            text = text[ConclusionsStart+1:ConclusionsEnd+1] \n",
    "            \n",
    "            # get rid of the weird lines\n",
    "            text = [line for line in text if '**' not in line]\n",
    "            text = [line for line in text if 'recommendations have not been edited.' not in line]\n",
    "            text = [line for line in text if 'recommendations will not be edited.' not in line]\n",
    "            text = [line.replace('\\xd2','') for line in text]\n",
    "            text = [line.replace('\\t','') for line in text]\n",
    "            text = [line.lstrip(\" \") for line in text]\n",
    "            \n",
    "            # merge lines so that each line is its own paragraph, starting with a paragraph number\n",
    "            text = mergeLines(text)\n",
    "            \n",
    "            # get rid of that disclaimer paragraph\n",
    "            text = [line for line in text if 'endorsed by the working group' not in line.lower()]\n",
    "            \n",
    "            dic['text'] = text \n",
    "            \n",
    "            # append to list\n",
    "            l.append(dic)\n",
    "              \n",
    "        except Exception,e:\n",
    "            broken.append(file_name +str(e)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Chunk into sections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1\n",
    "\n",
    "We'll first be working with a single UPR report. Make an object called `upr` that contains the fifth item in the list `l.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# assign `upr` as the fifth item in the list\n",
    "upr = l[4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2\n",
    "\n",
    "These texts have 3 sections each. The first section contains those recommendations the country supports. The second section contains recs the country will consider. The third contains recommendations the country explicitely rejects. \n",
    "\n",
    "Each section starts with a main paragraph number (e.g. **123**. The individual recommendations are then noted as subparagraphs (e.g. **123.1, 123.2** etc.\n",
    "\n",
    "The problem is, we don't know what these paragarph numbers are *a priori*. Luckily, Rochelle wrote you a function that passes a document and retuns the main paragraph numbers in that document's \"Conclusions and Recommendations\" section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(113, 114, 115)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# function to find main paragraphs numbers in each upr\n",
    "def mainParagraphs(upr):\n",
    "    '''\n",
    "    This function takes in a upr and returns the main paragraph numbers in the 'recommendations' section.\n",
    "    '''\n",
    "    firstParagraph = upr['text'][0].partition(\" \")[0]\n",
    "    if '.' in firstParagraph:\n",
    "            firstParagraph = firstParagraph.replace(\".\",\"\")\n",
    "    \n",
    "    # the first section containts the supported recs\n",
    "    firstParagraph = int(firstParagraph)\n",
    "    \n",
    "    # the second section contains the considered recs\n",
    "    secondParagraph = firstParagraph + 1\n",
    "    \n",
    "    # the third section contains the rejected recs\n",
    "    thirdParagraph = secondParagraph + 1\n",
    "    \n",
    "    return(firstParagraph, secondParagraph, thirdParagraph)\n",
    "\n",
    "# Uncomment to test\n",
    "mainParagraphs(upr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In your own words, explain how this function works. Feel free to make new cells and explore each line of the function, and/or litter the function with print statements."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***YOUR ANSWER HERE***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3\n",
    "\n",
    "Using this function, create three new variables, `support_P`, `consider_P`, and `reject_P`. Each variable should point to the paragraph number that it associated with that section. In this case, `support_P` should point to `113`. \n",
    "\n",
    "**Important: Don't just assign the numbers. Remember, we're going to generalize this code for all the uprs, and the individual paragraph numbers will change. So use the results from the function above.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113\n",
      "114\n",
      "115\n"
     ]
    }
   ],
   "source": [
    "support_P = mainParagraphs(upr)[0]\n",
    "consider_P = mainParagraphs(upr)[1]\n",
    "reject_P = mainParagraphs(upr)[2]\n",
    "\n",
    "# test your code\n",
    "print support_P\n",
    "print consider_P\n",
    "print reject_P"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 \n",
    "\n",
    "Create a new dictionary called `sections`. The dictionary should have three keys: `support`, `consider`, and `implemented`. Each key should point to a list of lines in that section. Your final dictionary should look something like this:\n",
    "\n",
    "```\n",
    "{ 'support': [113. Some text, 113.1 An supported rec, 101.2 Another rec, 113.3 Even more...],\n",
    "    \n",
    "  'consider': [114. A new section, 114.1 A considered rec, 114.2 Even more recs, 114.3 You get the picture...] ,\n",
    "  \n",
    "  'reject': [115. The last section, 115.1 A rejected rec, 115.2 Even more recs, 115.3 Etc ...]\n",
    "}\n",
    "```\n",
    "\n",
    "*hint*: How do you know if a line belongs to a section? It starts with the main paragraph number for that section. So use the **.startswith()** method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['113.  The recommendations formulated during the interactive dialogue/listed below have been examined by the Plurinational State of Bolivia and enjoy the support of the State party: ',\n",
       " '113.1 Incorporate the Rome Statute into national law (Mexico); ',\n",
       " '113.2 Consider ratifying the United Nations Educational, Scientific and Cultural Organization (UNESCO) Convention against Discrimination in Education (Ghana); ',\n",
       " '113.3 Ratify the UNESCO Convention against Discrimination in Education and ensure that primary education is free and compulsory for all (Portugal); ',\n",
       " '113.4 Ratify the Protocol to the American Convention for Human Rights (Norway); ']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sections = {}\n",
    "sections['support'] = [s for s in upr['text'] if s.startswith(str(support_P))]\n",
    "sections['consider'] = [s for s in upr['text'] if s.startswith(str(consider_P))]\n",
    "sections['reject'] = [s for s in upr['text'] if s.startswith(str(reject_P))]\n",
    "\n",
    "# test your code\n",
    "sections['support'][:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5 Just keep recommendations\n",
    "\n",
    "Take a look at one of the sections in the `sections` dictionary. For each section, the first line is the header paragraph, explaining how these recommendations are linked (e.g. they've all been supported or rejected). Below that are the items belonging to that section, containing specific recommendations. The latter is what we really care about. So we can delete the first item of each list contained in the `sections` dictionary. \n",
    "\n",
    "Go ahead and delete the first line of the list values in `sections`.\n",
    "\n",
    "**Note: There are multiple ways to do this.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['113.1 Incorporate the Rome Statute into national law (Mexico); ',\n",
       " '113.2 Consider ratifying the United Nations Educational, Scientific and Cultural Organization (UNESCO) Convention against Discrimination in Education (Ghana); ',\n",
       " '113.3 Ratify the UNESCO Convention against Discrimination in Education and ensure that primary education is free and compulsory for all (Portugal); ',\n",
       " '113.4 Ratify the Protocol to the American Convention for Human Rights (Norway); ',\n",
       " '113.5 Further strengthening, as to its funding and independence, of the national preventive mechanism under the Optional Protocol to the Convention against Torture (OP-CAT) so that it can function effectively and impartially (Czech Republic); ']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for key in sections.keys():\n",
    "    sections[key] = sections[key][1:]\n",
    "    \n",
    "# test your code\n",
    "sections['support'][:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.  Make a function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 \n",
    "\n",
    "We want to do the above parsing for each document in the list. Using the code you wrote in sections 1, write a function that passes a document (from the original `upr` list), and returns an dictionary object `sections`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# turn it into a function\n",
    "def parse(document):\n",
    "    \n",
    "    upr = document\n",
    "    \n",
    "    # find the paragraph numbers associated with each section\n",
    "    support_P = mainParagraphs(upr)[0]\n",
    "    consider_P = mainParagraphs(upr)[1]\n",
    "    reject_P = mainParagraphs(upr)[2]\n",
    "    \n",
    "    # separate upr out into chunks by mainP, i.e. the support, reject, consider chunks \n",
    "    # by identifying subparagraphs that start with the main paragraph numbers.\n",
    "    sections = {}\n",
    "    sections['support'] = [s for s in upr['text'] if s.startswith(str(support_P))]\n",
    "    sections['consider'] = [s for s in upr['text'] if s.startswith(str(consider_P))]\n",
    "    sections['reject'] = [s for s in upr['text'] if s.startswith(str(reject_P))]\n",
    "    \n",
    "    for key in sections.keys():\n",
    "        sections[key] = sections[key][1:]\n",
    "    \n",
    "    return(sections)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 \n",
    "\n",
    "Loop through all the dictionaries in the list `l` and assign a new `sections` key to the output from the above function. When you're done, your list `l` should contain items that look like this (remember: dictionaries are unordered):\n",
    "\n",
    "```\n",
    "[ \n",
    "    {'country': 'afghanistan',\n",
    "     'year': '2014'\n",
    "     'sections': {'support': <some list>,\n",
    "                  'consider': <some list>,\n",
    "                  'reject': <some list>,\n",
    "                } \n",
    "      }\n",
    "                  \n",
    "     \n",
    "     {'country': 'albania',\n",
    "      'year': '2014'\n",
    "      'sections': {'support': <some list>,\n",
    "                  'consider': <some list>,\n",
    "                  'reject': <some list>,\n",
    "                }\n",
    "      }                 \n",
    "                  \n",
    "```               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['136.1 To further build up on its effort to fully protect human rights in the country (Ethiopia); ',\n",
       " '136.2 Continue and deepen efforts to firmly root human rights values and principles in the Government system, including through human rights training to state officials (Indonesia); ',\n",
       " '136.3 Make further efforts to ensure the implementation of the legal framework which guarantees human rights, including the Constitution (Japan); ',\n",
       " '136.4 Further fulfil the internationally taken human rights obligations as well as integrate them into the national legislation (Kazakhstan); ',\n",
       " '136.5 Further strengthen its efforts to review its legislative framework and make necessary adjustments to it in order to ensure that it is in conformity with Afghanistan\\xd5s international human rights obligations (Norway); ']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# apply to all docs\n",
    "for i in l:\n",
    "    i['sections'] = parse(i)\n",
    "\n",
    "#uncomment to test\n",
    "l[0]['sections']['support'][:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Get information about specific recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 \n",
    "\n",
    "Take a look at a recommendation. I've given you a sample one below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "136.1 To further build up on its effort to fully protect human rights in the country (Ethiopia); \n"
     ]
    }
   ],
   "source": [
    "# get the first line, from the first section, of the first upr in `l`\n",
    "rec = l[0]['sections']['support'][0]\n",
    "print rec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that they're all formatted the same way, with the recommending country in parenthesis at the end, in between parentheses.\n",
    "\n",
    "In the cell below, find a way to pull out the recommending country. (Hint: Use the `split` method.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ethiopia'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# your code here\n",
    "rec.split('(')[-1].split(')')[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 \n",
    "\n",
    "Create a function called `get_country` that passes an individual recommendation and returns the recommending country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ethiopia'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_country(rec):\n",
    "    country = rec.split('(')[-1].split(')')[0]\n",
    "    return(country)\n",
    "\n",
    "# test youc ode\n",
    "get_country(l[0]['sections']['support'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3\n",
    "\n",
    "We now want to create a new list called `reclist` containing just individual recommendations. Each recommendation should be a dictionary with the following keys: \n",
    "\n",
    "1. `to`: the country under review\n",
    "2. `from`: the country (or countries) giving the recommendation\n",
    "4. `year`: the year of the review (all 2014 here)\n",
    "5. `decision`: whether the recommendation was supported, rejected, etc.\n",
    "6. `text`: the text of the recommendation\n",
    "\n",
    "Create your `reclist` by looping through your list `l`. (Hint: You'll need to use loops within loops.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2772\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'decision': 'support',\n",
       " 'from': 'Indonesia',\n",
       " 'text': '136.2 Continue and deepen efforts to firmly root human rights values and principles in the Government system, including through human rights training to state officials (Indonesia); ',\n",
       " 'to': 'afghanistan',\n",
       " 'year': '2014'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make dictionaries for each individual recommendation item\n",
    "reclist = []\n",
    "for upr in l:\n",
    "    for decision in upr['sections'].keys():\n",
    "        items = upr['sections'][decision]\n",
    "        for rec in items:\n",
    "            dic = {}\n",
    "            dic['to'] = upr['country']\n",
    "            dic['year'] = upr['year']\n",
    "            dic['decision'] = decision\n",
    "            dic['from'] = get_country(rec)\n",
    "            dic['text'] = rec\n",
    "            reclist.append(dic)  \n",
    "\n",
    "# uncomment to test\n",
    "print len(reclist)\n",
    "reclist[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Write a CSV\n",
    "\n",
    "We know want to write a csv file containing the information from `reclist`\n",
    "\n",
    "To do this, first create a variable called `keys` containing the keys from the first dictionary in `reclist`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['text', 'to', 'decision', 'from', 'year']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#writing column headings\n",
    "keys = reclist[0].keys()\n",
    "keys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the `DictWriter` function from the `csv` module, write a csv list of `reclist` into a file called `upr-recs.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#writing the rest\n",
    "with open('upr-recs.csv', 'wb') as output_file:\n",
    "    dict_writer = csv.DictWriter(output_file, keys)\n",
    "    dict_writer.writeheader()\n",
    "    dict_writer.writerows(reclist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Gotcha!\n",
    "\n",
    "I lied. Not all the upr documents have just 3 paragraphs following the same structure. Some of them have 2. Some of them have 4. And while most have `supported` and `considered` as sections, others have recommendations they refer to as `already implemented`. \n",
    "\n",
    "To sum up, there are 4 kinds of sections contained in these documents:\n",
    "\n",
    "1. Supported recommendations\n",
    "2. Already implemented recommendations\n",
    "3. Considered recommendations\n",
    "4. Rejected recommendations\n",
    "\n",
    "But any combination of these four can be present in any given document. There's no way to tell, a priori, how many sections the \"Conclusions and Recommendations\" portion will contain.\n",
    "\n",
    "Write me an algorithm -- or a list of step-by-step instructions -- that walks me through how you would solve for this. That is, what extra steps would you have to include from the code above to get it to work? Remember, the final product has to be a CSV with each row being a recommendation, and a column for `year`, `to`, `from`, `text`, and `decision`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***YOUR ANSWER HERE***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*****"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optional Challenge\n",
    "\n",
    "Code it!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we have to re-load the data from the directory `txts-extra`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing afghanistan2014.txt...\n",
      "processing albania2014.txt...\n",
      "processing angola2014.txt...\n",
      "processing azerbaijan2013.txt...\n",
      "processing bahamas2013.txt...\n",
      "processing bangladesh2013.txt...\n",
      "processing barbados2013.txt...\n",
      "processing belize2013.txt...\n",
      "processing bhutan2014.txt...\n",
      "processing bolivia2014.txt...\n",
      "processing bosniaandherzegovina2014.txt...\n",
      "processing botswana2013.txt...\n",
      "processing bruneidarussalam2014.txt...\n",
      "processing burkinafaso2013.txt...\n",
      "processing burundi2013.txt...\n",
      "processing cambodia2014.txt...\n",
      "processing cameroon2013.txt...\n",
      "processing canada2013.txt...\n",
      "processing capeverde2013.txt...\n",
      "processing centralafricanrepublic2013.txt...\n",
      "processing chad2013.txt...\n",
      "processing chile2014.txt...\n",
      "processing china2013.txt...\n",
      "processing colombia2013.txt...\n",
      "processing comoros2014.txt...\n",
      "processing congo2013.txt...\n",
      "processing costarica2014.txt...\n",
      "processing cotedivoire2014.txt...\n",
      "processing cuba2013.txt...\n",
      "processing cyprus2014.txt...\n",
      "processing democraticpeoplesrepublicofkorea2014.txt...\n",
      "processing democraticrepublicofthecongo2014.txt...\n",
      "processing djibouti2013.txt...\n",
      "processing dominica2014.txt...\n",
      "processing dominicanrepublic2014.txt...\n",
      "processing egypt2014.txt...\n",
      "processing elsalvador2014.txt...\n",
      "processing eritrea2014.txt...\n",
      "processing ethiopia2014.txt...\n",
      "processing fiji2014.txt...\n",
      "processing france2013.txt...\n",
      "processing gambia2014.txt...\n",
      "processing germany2013.txt...\n",
      "processing guinea2014.txt...\n",
      "processing iran2014.txt...\n",
      "processing iraq2014.txt...\n",
      "processing israel2013.txt...\n",
      "processing italy2014.txt...\n",
      "processing jordan2013.txt...\n",
      "processing kazakhstan2014.txt...\n",
      "processing liechtenstein2013.txt...\n",
      "processing luxembourg2013.txt...\n",
      "processing Macedonia2014.txt...\n",
      "processing madagascar2014.txt...\n",
      "processing malaysia2013.txt...\n",
      "processing mali2013.txt...\n",
      "processing malta2013.txt...\n",
      "processing mauritius2013.txt...\n",
      "processing mexico2013.txt...\n",
      "processing monaco2013.txt...\n",
      "processing montenegro2013.txt...\n",
      "processing newzealand2014.txt...\n",
      "processing nicaragua2014.txt...\n",
      "processing nigeria2013.txt...\n",
      "processing norway2014.txt...\n",
      "processing portugal2014.txt...\n",
      "processing qatar2014.txt...\n",
      "processing romania2013.txt...\n",
      "processing russia2013.txt...\n",
      "processing sanmarino2014.txt...\n",
      "processing saudiarabia2013.txt...\n",
      "processing senegal2013.txt...\n",
      "processing serbia2013.txt...\n",
      "processing slovakia2014.txt...\n",
      "processing slovenia2014.txt...\n",
      "processing tonga2013.txt...\n",
      "processing turkmenistan2013.txt...\n",
      "processing tuvalu2013.txt...\n",
      "processing unitedarabemirates2013.txt...\n",
      "processing uruguay2014.txt...\n",
      "processing uzbekistan2013.txt...\n",
      "processing vanuatu2014.txt...\n",
      "processing vietnam2014.txt...\n",
      "processing yemen2014.txt...\n"
     ]
    }
   ],
   "source": [
    "l=[]\n",
    "dir = 'data/txts-extra'\n",
    "for file_name in os.listdir(dir):\n",
    "    broken = []\n",
    "    if file_name.endswith(\".txt\"):\n",
    "        print 'processing ' + file_name + '...'\n",
    "        try:\n",
    "            dic = {}\n",
    "            dic['country'] = file_name[:-8]\n",
    "            dic['year'] = file_name[-8:-4]\n",
    "            f = open(dir + '/' + file_name,'rU')\n",
    "            text = f.read() # read in text\n",
    "            f.close\n",
    "            text = text.split('\\n') # make a list\n",
    "            text = filter(None, text) # get rid of empty string items       \n",
    "             \n",
    "            # take only the conclusions and/or recommendations section\n",
    "            ConclusionsStart = text.index([line for line in text if \"conclusions and/or recommendations\" in line.lower()][1]) #startin from bottom\n",
    "            ConclusionsEnd = text.index([line for line in text if \"conclusions and/or recommendations\" in line.lower()][2]) # the last one is the disclaimer\n",
    "            text = text[ConclusionsStart+1:ConclusionsEnd+1] \n",
    "            \n",
    "            # get rid of the weird lines\n",
    "            text = [line for line in text if '**' not in line]\n",
    "            text = [line for line in text if 'recommendations have not been edited.' not in line]\n",
    "            text = [line for line in text if 'recommendations will not be edited.' not in line]\n",
    "            text = [line.replace('\\xd2','') for line in text]\n",
    "            text = [line.replace('\\t','') for line in text]\n",
    "            text = [line.lstrip(\" \") for line in text]\n",
    "            \n",
    "            # merge lines so that each line is its own paragraph, starting with a paragraph number\n",
    "            text = mergeLines(text)\n",
    "            \n",
    "            # get rid of that disclaimer paragraph\n",
    "            text = [line for line in text if 'endorsed by the working group' not in line.lower()]\n",
    "            \n",
    "            dic['text'] = text \n",
    "            \n",
    "            # append to list\n",
    "            l.append(dic)\n",
    "              \n",
    "        except Exception,e:\n",
    "            broken.append(file_name +str(e)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we change the `mainParagraphs` function so that it gives us all the main paragraph numbers in the document. Note that this function does not assume 3 functions. If the document has 2 main sections, it'll give us 2 numbers. If it has 4 main sections, it'll give us 4 numbers, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{109, 110}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# function to find main paragraphs numbers in each upr\n",
    "def mainParagraphs(upr):\n",
    "    '''\n",
    "    This function takes in a upr and returns the main paragraph numbers in the 'recommendations' section.\n",
    "    There are usually 2-4 main paragraphs. Sometimes I refer to these main paragraph sections as \"chunks\".\n",
    "    '''    \n",
    "    mainParagraphs = []\n",
    "    for line in upr['text']:\n",
    "        paragraph = line.partition(\" \")[0]\n",
    "        if paragraph[-1] == '.':\n",
    "            paragraph = paragraph[:-1]\n",
    "                \n",
    "        mainParagraphs.append(float(paragraph))\n",
    "        \n",
    "    mainParagraphs = set([int(n) for n in mainParagraphs])\n",
    "    return mainParagraphs \n",
    "\n",
    "# Uncomment to test\n",
    "mainParagraphs(l[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we create a function (similar to `parse` in 2.1) that does the following:\n",
    "1. inputs a dictionary from `l` that represents a document\n",
    "2. outputs a list, `sections`, that holds 2-4 dictionaries, each dictionary representing a section in the document. So instead of `sections` being a dictionary (as above) it is now a list of dictionaries, with each dictionary having two keys: 'decision' (support, reject, etc) and 'items' (list of recs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# turn it into a function\n",
    "def parse(upr):\n",
    "    \n",
    "    # separate upr out into chunks by mainP, i.e. the support, reject, consider chunks \n",
    "    # by identifying subparagraphs that start with the main paragraph numbers.\n",
    "    sections = []\n",
    "    for n in mainParagraphs(upr):\n",
    "        dic = {}\n",
    "        dic['paragraph'] = n\n",
    "        dic['text'] = [s for s in upr['text'] if s.startswith(str(n))]\n",
    "        sections.append(dic)\n",
    "    \n",
    "    # delete all the chunks with only 1 paragraph -- these don't actually contain any recs.\n",
    "    for dic in sections:\n",
    "        if len(dic['text']) == 1:\n",
    "            sections.remove(dic)\n",
    "    \n",
    "    # parse into header (first line) and items (list of recommendations)\n",
    "    for dic in sections:\n",
    "        dic['header'] = dic['text'][0]\n",
    "        dic['items'] = dic['text'][1:]\n",
    "    \n",
    "    # assign a decision\n",
    "    for dic in sections: \n",
    "        text = dic['header'] \n",
    "        decision = ''\n",
    "        if 'implemented' in text or 'process of implementation' in text:\n",
    "            decision = 'implemented'\n",
    "        elif 'will be examined' in text or 'will examine' in text or \"further examined\" in text or \\\n",
    "        \"Responses to the following recommendations will be provided\" in text or \\\n",
    "        \"will be included in the outcome report\" in text or \"will be provided in due course\" in text or \\\n",
    "        \"course of the discussion\" in text:\n",
    "            decision = 'consider'\n",
    "        elif 'not enjoy the support' in text or 'reject' in text or 'cannot be accepted' in text:\n",
    "            decision = 'reject'\n",
    "        elif 'support' in text and 'did not enjoy the support' not in text:\n",
    "            decision = 'support'\n",
    "        elif 'have been noted by' in text or 'were noted by' in text:\n",
    "            decision = 'noted'\n",
    "        elif 'do not reflect the current situation' in text:\n",
    "            decision = 'reject'\n",
    "        else:\n",
    "            decision = 'unknown'\n",
    "        dic['decision'] = decision\n",
    "        \n",
    "    # delete unnecessary keys\n",
    "    for dic in sections:\n",
    "        del dic['text']\n",
    "        del dic['paragraph']\n",
    "        del dic['header']\n",
    "    \n",
    "    return(sections)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we loop through all the dictionaries in the list `l` and assign a new `sections` key to the output from the above function. When we're done, our list `l` should contain items that look like this (remember: dictionaries are unordered):\n",
    "```\n",
    "[ \n",
    "    {'country': 'afghanistan',\n",
    "     'year': '2014'\n",
    "     'sections' [\n",
    "                 {'decision': <some string>\n",
    "                  'items': <some list> },\n",
    "                 \n",
    "                 {'decision': <some string>\n",
    "                  'items': <some list> }\n",
    "                ] \n",
    "      }\n",
    "                  \n",
    "     \n",
    "     {'country': 'albania',\n",
    "      'year': '2014'\n",
    "      'sections' [\n",
    "                 {'decision': <some string>\n",
    "                  'items': <some list> },\n",
    "                 \n",
    "                 {'decision': <some string>\n",
    "                  'items': <some list> }\n",
    "                ] \n",
    "      }                 \n",
    "                  \n",
    "```   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'consider'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# apply to all docs\n",
    "for i in l:\n",
    "    i['sections'] = parse(i)\n",
    "\n",
    "#uncomment to test\n",
    "l[0]['sections'][1]['decision']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now want to create a new list called `reclist` containing just individual recommendations. Each recommendation should be a dictionary with the following keys: \n",
    "\n",
    "1. `to`: the country under review\n",
    "2. `from`: the country (or countries) giving the recommendation\n",
    "4. `year`: the year of the review (all 2014 here)\n",
    "5. `decision`: whether the recommendation was accepted, rejected, etc.\n",
    "6. `text`: the text of the recommendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14736\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'decision': 'consider',\n",
       " 'from': 'Estonia',\n",
       " 'text': '137.24 Ratify the Kampala Amendments to the Rome Statute and the Agreement on the Privileges and Immunities of the International Criminal Court (Estonia); ',\n",
       " 'to': 'afghanistan',\n",
       " 'year': '2014'}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make dictionaries for each individual recommendation item\n",
    "reclist = []\n",
    "for upr in l:\n",
    "    for section in upr['sections']:\n",
    "        for item in section['items']:\n",
    "            dic = {}\n",
    "            dic['to'] = upr['country']\n",
    "            dic['year'] = upr['year']\n",
    "            dic['decision'] = section['decision']\n",
    "            dic['from'] = item.split('(')[-1].split(')')[0]\n",
    "            dic['text'] = item\n",
    "            reclist.append(dic)  \n",
    "\n",
    "# uncomment to test\n",
    "print len(reclist)\n",
    "reclist[200]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Writing the csv is equivalent to above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
