```{r, include=FALSE}
knitr::opts_chunk$set(comment = "")
```

# Efficient Processing and Big Data: Problem Set

### Part 1
Suppose you have a data set containing five numeric, non-integer variables, and that there are no missing values.  Suppose further that you want to calculate the mean of the values contained in each row, and that you are trying to decide between several methods for this calculation, including a basic for loop, the built-in ```rowSums()``` function, the ```apply()``` function, and a parallelized ```foreach()``` call. 

1) Write a function that, for a given number of rows, creates a 5 column matrix filled with random samples from a standard normal distribution. Evaluate the function for 25 rows and print the results. 

```{r}
sim_mat<-function(n.rows){
  mat<-matrix(data = rnorm(n = n.rows*5), ncol = 5)
  return(mat)
}

print(sim_mat(n.rows = 25))
```

2) Write a function that, for a given matrix, calculates the row means using all four of the above methods and returns the elapsed time of execution for each calculation.  Get the execution times for a 100 row matrix created by your function from Question 1.

```{r}
sim_timer<-function(mat){
  
  library(foreach)
  library(doMC)
  registerDoMC()
  
  # For loop
  time.forloop<-system.time(expr = {
    rowmeans<-NULL
    for(row in 1:nrow(mat)){
      rowmeans[row]<-sum(mat[row,])/length(mat[row,])
    }
  })
  time.forloop<-time.forloop[3]
  
  # rowSums function
  time.rowsums<-system.time(expr = {
    rowmeans<-rowSums(x = mat)/ncol(mat)
  })
  time.rowsums<-time.rowsums[3]
  
  # Apply
  time.apply<-system.time(expr = {
    rowmeans<-apply(X = mat, MARGIN = 1, FUN = function(x){
      sum(x)/length(x)
    })
  })
  time.apply<-time.apply[3]

  # foreach (multiple cores)
  time.foreach<-system.time(expr = {
    rowmeans<-foreach(row=1:nrow(mat), .combine = c) %dopar% {
      sum(mat[row,])/length(mat[row,])
    }
  })
  time.foreach<-time.foreach[3]
  
  output<-data.frame(n.rows=nrow(mat),
             method=c("for loop", "rowSums", "apply", "foreach"),
             time=c(time.forloop, time.rowsums, time.apply, time.foreach), stringsAsFactors=F)
  
  return(output)
}

m<-sim_mat(n.rows = 100) 
sim_timer(m)
```

3) Create a plot showing how the execution time of each method changes as the number of rows in the matrix increases to 100k.  Which method completes the calculations the fastest?  Is the same method always fastest?   
```{r}
sim_results<-lapply(X = c(100,500,1000,5000,10000,50000,100000), FUN = function(x){
  m<-sim_mat(n.rows = x)
  sim_timer(mat = m)
})
sim_results<-do.call("rbind", sim_results)
library(ggplot2)
ggplot(data = sim_results, aes(x = n.rows, y = time, color=method))+geom_line(size=1)+theme_bw()
```




